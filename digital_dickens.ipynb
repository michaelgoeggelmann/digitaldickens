{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import tqdm as notebook_tqdm\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, OpenAI, PartOfSpeech\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "sys.path.insert(0, 'Path')\n",
    "from phd.letter import Letter\n",
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input (add recipients and time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def extract_paragraphs(letter_list):\n",
    "    ids = []\n",
    "    recipients = []\n",
    "    years = []\n",
    "    months = []\n",
    "    paragraphs = []\n",
    "    for letter in letter_list:\n",
    "        if letter.paragraphs:\n",
    "            for paragraph in letter.paragraphs:\n",
    "                paragraphs.append(paragraph)\n",
    "                ids.append(letter.id)\n",
    "                recipients.append(letter.recipient)\n",
    "                years.append(letter.year)\n",
    "                months.append(letter.month)\n",
    "        else:\n",
    "            paragraphs.append(letter.text)\n",
    "            ids.append(letter.id)\n",
    "            recipients.append(letter.recipient)\n",
    "            years.append(letter.year)\n",
    "            months.append(letter.month)\n",
    "    return paragraphs, ids, recipients, years, months\n",
    "\n",
    "def extract_text(letter_list):\n",
    "    ids = []\n",
    "    recipients = []\n",
    "    years = []\n",
    "    months = []\n",
    "    texts = []\n",
    "    for letter in letter_list:\n",
    "        texts.append(letter.text)\n",
    "        ids.append(letter.id)\n",
    "        recipients.append(letter.recipient)\n",
    "        years.append(letter.year)\n",
    "        months.append(letter.month)\n",
    "    return texts, ids, recipients, years, months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = \"letters\"\n",
    "\n",
    "data = load_data_from_pickle(pickle_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs, ids, recipients, years, months = extract_paragraphs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Whole Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, ids, recipients, years, months = extract_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Topic Models, Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in English stop words\n",
    "#english_stop_words = CountVectorizer(stop_words='english').get_stop_words()\n",
    "\n",
    "# Custom stop words\n",
    "#custom_stop_words = ['dickens', 'forster', 'coutts', 'couttss', 'mr', 'mrs', \"dickenss\", 'charles', 'kate', 'georgina', 'macready', 'arthur', 'smith', 'letter', 'write', 'forsters']\n",
    "\n",
    "# Combine both lists\n",
    "#all_stop_words = list(english_stop_words) + custom_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KeyBERT\n",
    "keybert_model = KeyBERTInspired()\n",
    "\n",
    "# GPT-3.5\n",
    "client = openai.OpenAI(api_key=\"drop_key_here\")\n",
    "prompt = \"\"\"\n",
    "I have a topic that contains the following documents: \n",
    "[DOCUMENTS]\n",
    "The topic is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "Based on the information above, extract a short but highly descriptive topic label of at most 5 words. Make sure it is in the following format:\n",
    "topic: <topic label>\n",
    "\"\"\"\n",
    "openai_model = OpenAI(client, model=\"gpt-3.5-turbo\", exponential_backoff=True, chat=True, prompt=prompt)\n",
    "\n",
    "# All representation models\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert_model\n",
    "    #,\"OpenAI\": openai_model,  # Uncomment if you will use OpenAI\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "#vectorizer_model = CountVectorizer(stop_words=all_stop_words)\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(paragraphs, show_progress_bar=True)\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reduce our embeddings to 2D as it will allows us to quickly iterate later on\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, \n",
    "                          min_dist=0.0, metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our topic model\n",
    "topic_model = BERTopic(embedding_model=sentence_model, umap_model=umap_model, representation_model=representation_model,\n",
    "                       vectorizer_model=vectorizer_model, calculate_probabilities=True)\n",
    "\n",
    "topics, probs = topic_model.fit_transform(paragraphs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('topics_with labels.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics(custom_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy(custom_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(ids, reduced_embeddings=reduced_embeddings, custom_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topics per category derived from the handbook\n",
    "\n",
    "# Data Preparation\n",
    "topic_counts = {\n",
    "    'Dreams': 2,\n",
    "    'Social Reform': 5,\n",
    "    'Affect and Emotions': 13,\n",
    "    'Animals and Nature': 4,\n",
    "    'Religion and Christmas': 6,\n",
    "    'Alcohol and Drinking': 3,\n",
    "    'Theatre and Shakespeare': 14\n",
    "}\n",
    "\n",
    "# Sorting the data based on passage counts for consistency\n",
    "sorted_categories = sorted(topic_counts, key=topic_counts.get, reverse=True)\n",
    "topics = [topic_counts[category] for category in sorted_categories]\n",
    "\n",
    "# Plotting the number of topics with a refined color palette\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sorted_categories, topics, color='#4a90e2', edgecolor='black')\n",
    "plt.xlabel('Category derived from the Oxford Handbook', fontsize=12)\n",
    "plt.ylabel('Number of assigned topics', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter paragraphs per category derived from the handbook\n",
    "\n",
    "# Data Preparation\n",
    "passage_counts = {\n",
    "    'Dreams': 65,\n",
    "    'Social Reform': 169,\n",
    "    'Affect and Emotions': 500,\n",
    "    'Animals and Nature': 162,\n",
    "    'Religion and Christmas': 190,\n",
    "    'Alcohol and Drinking': 122,\n",
    "    'Theatre and Shakespeare': 563\n",
    "}\n",
    "\n",
    "# Sorting the data based on passage counts for consistency\n",
    "sorted_categories = sorted(passage_counts, key=passage_counts.get, reverse=True)\n",
    "passages = [passage_counts[category] for category in sorted_categories]\n",
    "\n",
    "# Plotting the number of passages with a complementary color\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sorted_categories, passages, color='#e27d60', edgecolor='black')\n",
    "plt.xlabel('Category derived from the Oxford Handbook', fontsize=12)\n",
    "plt.ylabel('Number of assigned letter paragraphs', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics per category (other thematic trends)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data Preparation\n",
    "topic_counts = {\n",
    "    'Traveling and Places': 25,\n",
    "    'Supernatural, Mysticism, and Ghosts': 7,\n",
    "    'Clothing and Appearance': 3,\n",
    "    'Portraits and Photographs': 1,\n",
    "    'Health and Well-being': 6,\n",
    "    'Copyright and Piracy': 3,\n",
    "    'Poems, Poets, and Verses': 6\n",
    "}\n",
    "\n",
    "# Sorting the data based on passage counts for consistency\n",
    "sorted_categories = sorted(topic_counts, key=topic_counts.get, reverse=True)\n",
    "topics = [topic_counts[category] for category in sorted_categories]\n",
    "\n",
    "# Plotting the number of topics with a refined color palette\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sorted_categories, topics, color='#4a90e2', edgecolor='black')\n",
    "plt.xlabel('Other thematic trends', fontsize=12)\n",
    "plt.ylabel('Number of assigned topics', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter paragraphs per category (other thematic trends)\n",
    "\n",
    "# Data Preparation\n",
    "passage_counts = {'Traveling and Places': 1788, 'Supernatural, Mysticism, and Ghosts': 122, 'Clothing and Appearance': 163, 'Portraits and Photographs': 266, 'Health and Well-being': 291, 'Copyright and Piracy': 107, 'Poems, Poets, and Verses': 328}\n",
    "\n",
    "\n",
    "# Sorting the data based on passage counts for consistency\n",
    "sorted_categories = sorted(passage_counts, key=passage_counts.get, reverse=True)\n",
    "passages = [passage_counts[category] for category in sorted_categories]\n",
    "\n",
    "# Plotting the number of passages with a complementary color\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sorted_categories, passages, color='#e27d60', edgecolor='black')\n",
    "plt.xlabel('Other thematic trends', fontsize=12)\n",
    "plt.ylabel('Number of assigned letter paragraphs', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time = topic_model.topics_over_time(paragraphs, years, nr_bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_poems = topic_model.visualize_topics_over_time(topics_over_time, topics=[270,264,29,207,24,69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_all = topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=len(topics_over_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics per Recipient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(set(recipients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_class = topic_model.topics_per_class(paragraphs, classes=recipients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_topics=[270,264,29,207,24,69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows the recipient of every letter paragraph assigned to poem-related topics\n",
    "poem_df = topics_per_class[topics_per_class['Topic'].isin(poem_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the classes across all topics and sum the frequencies\n",
    "class_frequencies = poem_df.groupby('Class')['Frequency'].sum().reset_index()\n",
    "\n",
    "# Determine the classes with a frequency of more than 3\n",
    "major_classes = class_frequencies[class_frequencies['Frequency'] > 3]['Class'].tolist()\n",
    "\n",
    "# Replace all other classes with \"Misc.\"\n",
    "poem_df['Class'] = poem_df['Class'].apply(lambda x: x if x in major_classes else 'Misc.')\n",
    "\n",
    "# Aggregate the data by \"Topic\" and \"Class\"\n",
    "agg_df_with_misc = poem_df.groupby(['Topic', 'Class'])['Frequency'].sum().unstack(fill_value=0)\n",
    "\n",
    "# Sort the classes by their total frequency\n",
    "sorted_classes = agg_df_with_misc.sum().sort_values(ascending=False).index\n",
    "agg_df_with_misc = agg_df_with_misc[sorted_classes]\n",
    "\n",
    "# Add \"Misc.\" as the last category if it's not already there\n",
    "if 'Misc.' not in agg_df_with_misc.columns:\n",
    "    agg_df_with_misc['Misc.'] = 0\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = agg_df_with_misc.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='tab20')\n",
    "\n",
    "# Sort the legend by the total frequency of the classes\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "total_freq = agg_df_with_misc.sum().sort_values(ascending=False)\n",
    "print(total_freq)\n",
    "sorted_handles_labels = sorted(zip(handles, labels), key=lambda x: total_freq[x[1]], reverse=True)\n",
    "sorted_handles, sorted_labels = zip(*sorted_handles_labels)\n",
    "\n",
    "# Update the legend\n",
    "ax.legend(sorted_handles, sorted_labels, title='Class', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Classes by Topic')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar Topics per Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_topics, similarity = topic_model.find_topics(\"contract\", top_n=5)\n",
    "similar_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
